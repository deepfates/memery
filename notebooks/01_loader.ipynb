{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loader\n",
    "> Functions for finding and loading image files and saved embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: A lot of this implementation is too specific, especially the slugified filenames being used for dictionary IDs. Should be replaced with a better database implementation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def slugify(filepath):\n",
    "    return f'{filepath.stem}_{str(filepath.stat().st_mtime).split(\".\")[0]}'\n",
    "\n",
    "def get_image_files(path):\n",
    "    img_extensions = {'.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'}\n",
    "    return [(f, slugify(f)) for f in tqdm(path.rglob('*')) if f.suffix in img_extensions]\n",
    "\n",
    "def get_valid_images(path):\n",
    "    filepaths = get_image_files(path)\n",
    "    return [f for f in filepaths if verify_image(f[0])]\n",
    "\n",
    "# This returns boolean and should be called is_valid_image or something like that\n",
    "def verify_image(f):\n",
    "    try:\n",
    "        img = Image.open(f)\n",
    "        img.verify() \n",
    "        return(True)\n",
    "    except Exception as e:\n",
    "        print(f'Skipping bad file: {f}\\ndue to {type(e)}')\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating the usage here, not a great test though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 59419.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = Path('./images')\n",
    "\n",
    "\n",
    "filepaths = get_image_files(root)\n",
    "\n",
    "len(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(PosixPath('images/Wholesome-Meme-3.jpg'), 'Wholesome-Meme-3_1621298477'),\n",
       " (PosixPath('images/Wholesome-Meme-44.png'), 'Wholesome-Meme-44_1621298480'),\n",
       " (PosixPath('images/Wholesome-Meme-69.jpg'), 'Wholesome-Meme-69_1621298481')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders\n",
    "\n",
    "So we have a list of paths and slugified filenames from the folder. We want to see if there's an archive, so that we don't have to recalculate tensors for images we've seen before. Then we want to pass that directly to the indexer, but send the new images through the crafter and encoder first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the GPU, if possible, for all the pyTorch functions. But if we can't get access to it we need to fallback to CPU. Either way we call it `device` and pass it to each function in the executors that use torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `archive_loader` is only called in `indexFlow`. It takes the list of image files and the folder they're in (and the torch device), opens an archive if there is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def archive_loader(filepaths, root, device):\n",
    "    dbpath = root/'memery.pt'\n",
    "#     dbpath_backup = root/'memery.pt'\n",
    "    db = db_loader(dbpath, device)\n",
    "    \n",
    "    current_slugs = [slug for path, slug in filepaths]    \n",
    "    archive_db = {i:db[item[0]] for i, item in enumerate(db.items()) if item[1]['slug'] in current_slugs}      \n",
    "    archive_slugs = [v['slug'] for v in archive_db.values()]\n",
    "    new_files = [(str(path), slug) for path, slug in filepaths if slug not in archive_slugs and verify_image(path)]\n",
    "    \n",
    "    return(archive_db, new_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `db_loader` takes a location and returns either the archive dictionary or an empty dictionary. Decomposed to its own function so it can be called separately from `archive_loader` or `queryFlow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def db_loader(dbpath, device):\n",
    "\n",
    "    # check for savefile or backup and extract\n",
    "    if Path(dbpath).exists():\n",
    "        db = torch.load(dbpath, device)\n",
    "#     elif dbpath_backup.exists():\n",
    "#         db = torch.load(dbpath_backup)\n",
    "    else:\n",
    "        db = {}\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `annoy`, [Approximate Nearest Neighbors Oh Yeah!](https://github.com/spotify/annoy) allows us to search through vector space for approximate matches instead of exact best-similarity matches. We sacrifice accuracy for speed, so we can search through tens of thousands of images in less than a thousand times the time it would take to search through tens of images. There's got to be a better way to put that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def treemap_loader(treepath):\n",
    "    treemap = AnnoyIndex(512, 'angular')\n",
    "\n",
    "    if treepath.exists():\n",
    "        treemap.load(str(treepath))\n",
    "    else:\n",
    "        treemap = None\n",
    "    return(treemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treepath = Path('images/memery.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemap = AnnoyIndex(512, 'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if treepath.exists():\n",
    "    treemap.load(str(treepath))\n",
    "else:\n",
    "    treemap = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just test on the local image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 53092.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bad file: images/corrupted-file.jpeg\n",
      "due to <class 'PIL.UnidentifiedImageError'>\n",
      "Skipping bad file: images/.ipynb_checkpoints/corrupted-file-checkpoint.jpeg\n",
      "due to <class 'PIL.UnidentifiedImageError'>\n"
     ]
    }
   ],
   "source": [
    "archive_db, new_files = archive_loader(get_image_files(root), root, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 0, 80)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archive_db), len(new_files), treemap.get_n_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = root/'memery.pt'\n",
    "#     dbpath_backup = root/'memery.pt'\n",
    "db = db_loader(dbpath, device)\n",
    "\n",
    "current_slugs = [slug for path, slug in filepaths]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_db = {i:db[item[0]] for i, item in enumerate(db.items()) if item[1]['slug'] in current_slugs}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archive_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
