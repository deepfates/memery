{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular flow system\n",
    "\n",
    "I have decided to adapt the design system from Jina into this repo, at least for prototyping purposes. Their distributed systems approach seems quite good but is too muc complexity for me to add right away. Insetead I'm going to replicate the essential design pattern, that of Flows and Executors.\n",
    "\n",
    "**Flows** are specific patterns of data manipulation and storage. **Executors** are the operators that transform the data within the flow. \n",
    "\n",
    "There are two core flows to any search system: indexing, and querying. The plan here is to make executors that can be composed into flows and then compose the flows into a UI that supports querying and, to some extent, indexing as well.\n",
    "\n",
    "The core executors for this use case are:\n",
    " - Loader\n",
    " - Crafter\n",
    " - Encoder\n",
    " - Indexer\n",
    " - Ranker\n",
    " - Gateway\n",
    " \n",
    "In this file I try to build these so that the Jupyter notebook itself can be run as a Flow for indexing and then querying. From there it should be easy to abstract the functions and classes and messaging or whatever is necessary for microservices etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.215480Z",
     "iopub.status.busy": "2021-05-17T23:26:12.215153Z",
     "iopub.status.idle": "2021-05-17T23:26:12.218180Z",
     "shell.execute_reply": "2021-05-17T23:26:12.217661Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.215435Z"
    }
   },
   "outputs": [],
   "source": [
    "# move these to main function eventually but for now we're going in notebook order\n",
    "args = {\n",
    "    \"path\": \"/home/mage/Pictures/memes/\",\n",
    "    \"query\": \"scary cat\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader\n",
    "\n",
    "The loader takes a directory or list of image files and checks them against database or checkpoint. If there is a saved checkpoint and the files haven't changed, it loads the checkpoint and sends the data directly to Ranker. If not, it sends them to Crafter. Ideally  it could send new images to Crafter and load dictionary of old images at the same time, without re-encoding old images.\n",
    "\n",
    "The process of indexing could actually happen in the background while querying happens on the old index! This means putting the logic in the Flow rather than the Loader, I suppose.\n",
    "\n",
    "Maybe build dictionary `{filename_timestamp : vector}` to databse as a simple version control mechanism. Then, if any filenames exist but with a different timestamp, we load those under their own key. And we can throw out any filename_timestamp that doesn't exist, before indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.219219Z",
     "iopub.status.busy": "2021-05-17T23:26:12.218988Z",
     "iopub.status.idle": "2021-05-17T23:26:12.221615Z",
     "shell.execute_reply": "2021-05-17T23:26:12.221131Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.219201Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path(args['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.222765Z",
     "iopub.status.busy": "2021-05-17T23:26:12.222612Z",
     "iopub.status.idle": "2021-05-17T23:26:12.225218Z",
     "shell.execute_reply": "2021-05-17T23:26:12.224478Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.222747Z"
    }
   },
   "outputs": [],
   "source": [
    "def slugify(filepath):\n",
    "    return f'{filepath.stem}_{str(filepath.stat().st_mtime).split(\".\")[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.226412Z",
     "iopub.status.busy": "2021-05-17T23:26:12.226182Z",
     "iopub.status.idle": "2021-05-17T23:26:12.229182Z",
     "shell.execute_reply": "2021-05-17T23:26:12.228619Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.226386Z"
    }
   },
   "outputs": [],
   "source": [
    "# filenames = path.iterdir()\n",
    "def get_image_files(path):\n",
    "    return [(f, slugify(f)) for f in path.rglob('*') if f.suffix in ['.jpg', '.png', '.jpeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.230161Z",
     "iopub.status.busy": "2021-05-17T23:26:12.229994Z",
     "iopub.status.idle": "2021-05-17T23:26:12.271774Z",
     "shell.execute_reply": "2021-05-17T23:26:12.271310Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.230139Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths = get_image_files(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.272506Z",
     "iopub.status.busy": "2021-05-17T23:26:12.272342Z",
     "iopub.status.idle": "2021-05-17T23:26:12.279507Z",
     "shell.execute_reply": "2021-05-17T23:26:12.279149Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.272456Z"
    }
   },
   "outputs": [],
   "source": [
    "len(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.280416Z",
     "iopub.status.busy": "2021-05-17T23:26:12.280299Z",
     "iopub.status.idle": "2021-05-17T23:26:12.283291Z",
     "shell.execute_reply": "2021-05-17T23:26:12.282872Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.280400Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a list of paths and slugified filenames from the folder. We want to see if there's an archive, so that we don't have to recalculate tensors for images we've seen before. Then we want to pass that directly to the indexer, but send the new images through the crafter and encoder first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T23:37:14.029490Z",
     "iopub.status.busy": "2021-05-12T23:37:14.028825Z",
     "iopub.status.idle": "2021-05-12T23:37:14.080913Z",
     "shell.execute_reply": "2021-05-12T23:37:14.080380Z",
     "shell.execute_reply.started": "2021-05-12T23:37:14.029406Z"
    }
   },
   "source": [
    "But I need to separate out the logic for the crafter and encoder from the simple loading of archives and pictures. This component should only provide the dictionary of archived CLIP embeddings, the treemap (eventually) and the locations of the new images to review, and let the downstream components deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.283975Z",
     "iopub.status.busy": "2021-05-17T23:26:12.283864Z",
     "iopub.status.idle": "2021-05-17T23:26:12.768725Z",
     "shell.execute_reply": "2021-05-17T23:26:12.768101Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.283960Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.770648Z",
     "iopub.status.busy": "2021-05-17T23:26:12.770436Z",
     "iopub.status.idle": "2021-05-17T23:26:12.775477Z",
     "shell.execute_reply": "2021-05-17T23:26:12.774783Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.770627Z"
    }
   },
   "outputs": [],
   "source": [
    "def files_archive_loader(filepaths, root, device):\n",
    "    dbpath = root/'memery.pt'\n",
    "#     dbpath_backup = root/'memery.pt'\n",
    "    db = db_loader(dbpath)\n",
    "    \n",
    "    current_slugs = [slug for path, slug in filepaths]    \n",
    "    archive_db = {k:db[k] for k in db if k in current_slugs}   \n",
    "    archive_slugs = [v['slug'] for v in archive_db.values()]\n",
    "    new_files = [(str(path), slug) for path, slug in filepaths if slug not in archive_slugs]\n",
    "    \n",
    "    return(archive_db, new_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.778681Z",
     "iopub.status.busy": "2021-05-17T23:26:12.778540Z",
     "iopub.status.idle": "2021-05-17T23:26:12.781397Z",
     "shell.execute_reply": "2021-05-17T23:26:12.780882Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.778662Z"
    }
   },
   "outputs": [],
   "source": [
    "def db_loader(dbpath):\n",
    "    # check for savefile or backup and extract\n",
    "    if dbpath.exists():\n",
    "        db = torch.load(dbpath)\n",
    "#     elif dbpath_backup.exists():\n",
    "#         db = torch.load(dbpath_backup)\n",
    "    else:\n",
    "        db = {}\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.782479Z",
     "iopub.status.busy": "2021-05-17T23:26:12.782283Z",
     "iopub.status.idle": "2021-05-17T23:26:12.785981Z",
     "shell.execute_reply": "2021-05-17T23:26:12.785150Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.782459Z"
    }
   },
   "outputs": [],
   "source": [
    "def treemap_loader(treepath):\n",
    "    treemap = AnnoyIndex(512, 'angular')\n",
    "\n",
    "    if treepath.exists():\n",
    "        treemap.load(str(treepath))\n",
    "    else:\n",
    "        treemap = None\n",
    "    return(treemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:12.787044Z",
     "iopub.status.busy": "2021-05-17T23:26:12.786880Z",
     "iopub.status.idle": "2021-05-17T23:26:14.981021Z",
     "shell.execute_reply": "2021-05-17T23:26:14.980482Z",
     "shell.execute_reply.started": "2021-05-17T23:26:12.787026Z"
    }
   },
   "outputs": [],
   "source": [
    "archive_db, new_files = files_archive_loader(get_image_files(Path(args['path'])), root, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:14.982030Z",
     "iopub.status.busy": "2021-05-17T23:26:14.981859Z",
     "iopub.status.idle": "2021-05-17T23:26:14.986891Z",
     "shell.execute_reply": "2021-05-17T23:26:14.986449Z",
     "shell.execute_reply.started": "2021-05-17T23:26:14.982010Z"
    }
   },
   "outputs": [],
   "source": [
    "len(archive_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:14.987764Z",
     "iopub.status.busy": "2021-05-17T23:26:14.987610Z",
     "iopub.status.idle": "2021-05-17T23:26:14.991252Z",
     "shell.execute_reply": "2021-05-17T23:26:14.990625Z",
     "shell.execute_reply.started": "2021-05-17T23:26:14.987747Z"
    }
   },
   "outputs": [],
   "source": [
    "len(new_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:14.992366Z",
     "iopub.status.busy": "2021-05-17T23:26:14.992157Z",
     "iopub.status.idle": "2021-05-17T23:26:14.996332Z",
     "shell.execute_reply": "2021-05-17T23:26:14.995383Z",
     "shell.execute_reply.started": "2021-05-17T23:26:14.992343Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "len(new_files),len(archive_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crafter\n",
    "\n",
    "Takes a list of image filenames and transforms them to batches of the correct dimensions for CLIP. Need to figure out a way around torchvision's loader  idiosyncrasies here: currently it just loads images from subfolders, needs to operate okay if pointed at a single folder of images, or recursively, or an arbitrary list of files.\n",
    "\n",
    "Then, too, it would be nice to eventually putthis work on the client computer using torchscript or something. So that it only sends 224x224x3 images over the wire. And we only have to compute those once per image, since we're storing a database of finished vectors which should be even smaller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:14.997972Z",
     "iopub.status.busy": "2021-05-17T23:26:14.997652Z",
     "iopub.status.idle": "2021-05-17T23:26:15.000660Z",
     "shell.execute_reply": "2021-05-17T23:26:15.000138Z",
     "shell.execute_reply.started": "2021-05-17T23:26:14.997945Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:15.005865Z",
     "iopub.status.busy": "2021-05-17T23:26:15.005459Z",
     "iopub.status.idle": "2021-05-17T23:26:15.010256Z",
     "shell.execute_reply": "2021-05-17T23:26:15.009011Z",
     "shell.execute_reply.started": "2021-05-17T23:26:15.005837Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataset(new_files):\n",
    "    '''Returns a list of samples of a form (path_to_sample, class) and in \n",
    "    this case the class is just the filename'''\n",
    "    samples = []\n",
    "    slugs = []\n",
    "    for i, f in enumerate(new_files):\n",
    "        path, slug = f\n",
    "        samples.append((str(path), i))\n",
    "        slugs.append((slug, i))\n",
    "    return(samples, slugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:15.011746Z",
     "iopub.status.busy": "2021-05-17T23:26:15.011203Z",
     "iopub.status.idle": "2021-05-17T23:26:15.015031Z",
     "shell.execute_reply": "2021-05-17T23:26:15.014629Z",
     "shell.execute_reply.started": "2021-05-17T23:26:15.011681Z"
    }
   },
   "outputs": [],
   "source": [
    "def pil_loader(path: str) -> Image.Image:\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:15.015970Z",
     "iopub.status.busy": "2021-05-17T23:26:15.015807Z",
     "iopub.status.idle": "2021-05-17T23:26:15.020168Z",
     "shell.execute_reply": "2021-05-17T23:26:15.019612Z",
     "shell.execute_reply.started": "2021-05-17T23:26:15.015951Z"
    }
   },
   "outputs": [],
   "source": [
    "class DatasetImagePaths(VisionDataset):\n",
    "    def __init__(self, new_files, transforms = None):\n",
    "        super(DatasetImagePaths, self).__init__(new_files, transforms=transforms)\n",
    "        samples, slugs = make_dataset(new_files)\n",
    "        self.samples = samples\n",
    "        self.slugs = slugs\n",
    "        self.loader = pil_loader\n",
    "        self.root = 'file dataset'\n",
    "    def __len__(self):\n",
    "        return(len(self.samples))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:15.021137Z",
     "iopub.status.busy": "2021-05-17T23:26:15.020930Z",
     "iopub.status.idle": "2021-05-17T23:26:15.024133Z",
     "shell.execute_reply": "2021-05-17T23:26:15.023597Z",
     "shell.execute_reply.started": "2021-05-17T23:26:15.021117Z"
    }
   },
   "outputs": [],
   "source": [
    "crafted = DatasetImagePaths(new_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:10.327359Z",
     "iopub.status.busy": "2021-05-17T23:27:10.327061Z",
     "iopub.status.idle": "2021-05-17T23:27:10.331376Z",
     "shell.execute_reply": "2021-05-17T23:27:10.330348Z",
     "shell.execute_reply.started": "2021-05-17T23:27:10.327324Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(crafted) > 0:\n",
    "    crafted[0][0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that seems to work decently. Test with transforms, which I will just find in CLIP source code and copy over, to prevent having to import CLIP in this executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:10.532077Z",
     "iopub.status.busy": "2021-05-17T23:27:10.531910Z",
     "iopub.status.idle": "2021-05-17T23:27:10.535139Z",
     "shell.execute_reply": "2021-05-17T23:27:10.534199Z",
     "shell.execute_reply.started": "2021-05-17T23:27:10.532056Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:10.672197Z",
     "iopub.status.busy": "2021-05-17T23:27:10.672025Z",
     "iopub.status.idle": "2021-05-17T23:27:10.675311Z",
     "shell.execute_reply": "2021-05-17T23:27:10.674703Z",
     "shell.execute_reply.started": "2021-05-17T23:27:10.672178Z"
    }
   },
   "outputs": [],
   "source": [
    "def clip_transform(n_px):\n",
    "    return Compose([\n",
    "        Resize(n_px, interpolation=Image.BICUBIC),\n",
    "        CenterCrop(n_px),\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:10.783218Z",
     "iopub.status.busy": "2021-05-17T23:27:10.783066Z",
     "iopub.status.idle": "2021-05-17T23:27:10.785719Z",
     "shell.execute_reply": "2021-05-17T23:27:10.785213Z",
     "shell.execute_reply.started": "2021-05-17T23:27:10.783202Z"
    }
   },
   "outputs": [],
   "source": [
    "crafted_transformed = DatasetImagePaths(new_files, clip_transform(224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:10.914257Z",
     "iopub.status.busy": "2021-05-17T23:27:10.914086Z",
     "iopub.status.idle": "2021-05-17T23:27:10.916361Z",
     "shell.execute_reply": "2021-05-17T23:27:10.915817Z",
     "shell.execute_reply.started": "2021-05-17T23:27:10.914238Z"
    }
   },
   "outputs": [],
   "source": [
    "# crafted_transformed[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:11.049878Z",
     "iopub.status.busy": "2021-05-17T23:27:11.049661Z",
     "iopub.status.idle": "2021-05-17T23:27:11.052757Z",
     "shell.execute_reply": "2021-05-17T23:27:11.052083Z",
     "shell.execute_reply.started": "2021-05-17T23:27:11.049856Z"
    }
   },
   "outputs": [],
   "source": [
    "# to_pil = torchvision.transforms.ToPILImage()\n",
    "# img = to_pil(crafted_transformed[0][0])\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put that all together, and wrap in a DataLoader for batching. In future, need to figure out how to pick batch size and number of workers programmatically bsed on device capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:11.510935Z",
     "iopub.status.busy": "2021-05-17T23:27:11.510756Z",
     "iopub.status.idle": "2021-05-17T23:27:11.514316Z",
     "shell.execute_reply": "2021-05-17T23:27:11.513561Z",
     "shell.execute_reply.started": "2021-05-17T23:27:11.510917Z"
    }
   },
   "outputs": [],
   "source": [
    "def crafter(new_files, device, batch_size=128, num_workers=4): \n",
    "    with torch.no_grad():\n",
    "        imagefiles=DatasetImagePaths(new_files, clip_transform(224))\n",
    "        img_loader=torch.utils.data.DataLoader(imagefiles, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return(img_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:11.876682Z",
     "iopub.status.busy": "2021-05-17T23:27:11.876512Z",
     "iopub.status.idle": "2021-05-17T23:27:11.880238Z",
     "shell.execute_reply": "2021-05-17T23:27:11.879080Z",
     "shell.execute_reply.started": "2021-05-17T23:27:11.876665Z"
    }
   },
   "outputs": [],
   "source": [
    "img_loader = crafter(new_files, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:12.182811Z",
     "iopub.status.busy": "2021-05-17T23:27:12.182645Z",
     "iopub.status.idle": "2021-05-17T23:27:12.186305Z",
     "shell.execute_reply": "2021-05-17T23:27:12.185653Z",
     "shell.execute_reply.started": "2021-05-17T23:27:12.182794Z"
    }
   },
   "outputs": [],
   "source": [
    "img_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "CLIP wrapper takes batched tensors or text queries and returns batched 512-dim vectors. size of batch depends on GPU, but if we're putting all that on a server anyway it's a matter of accounting. Does batching go here though? Or in the crafter?\n",
    "\n",
    "cool thing here is we can use one encoder for both image and text, just check type on the way in. but first probably keep it simple and make two functions.\n",
    "\n",
    "could index previous queries as vectors in a different map and use for predictive/history -- keep a little database of previous queries already in vector format and their ranked NNs, so that the user can see history offline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:13.353998Z",
     "iopub.status.busy": "2021-05-17T23:27:13.353324Z",
     "iopub.status.idle": "2021-05-17T23:27:14.660546Z",
     "shell.execute_reply": "2021-05-17T23:27:14.659900Z",
     "shell.execute_reply.started": "2021-05-17T23:27:13.353916Z"
    }
   },
   "outputs": [],
   "source": [
    "import clip\n",
    "from tqdm import tqdm\n",
    "model, _ = clip.load(\"ViT-B/32\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:14.661653Z",
     "iopub.status.busy": "2021-05-17T23:27:14.661465Z",
     "iopub.status.idle": "2021-05-17T23:27:14.665037Z",
     "shell.execute_reply": "2021-05-17T23:27:14.664655Z",
     "shell.execute_reply.started": "2021-05-17T23:27:14.661618Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_encoder(img_loader, device):\n",
    "    image_embeddings = torch.tensor(()).to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(img_loader):\n",
    "            batch_features = model.encode_image(images)\n",
    "            image_embeddings = torch.cat((image_embeddings, batch_features)).to(device)\n",
    "    \n",
    "    image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
    "    return(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:15.166413Z",
     "iopub.status.busy": "2021-05-17T23:27:15.166108Z",
     "iopub.status.idle": "2021-05-17T23:27:15.300321Z",
     "shell.execute_reply": "2021-05-17T23:27:15.299842Z",
     "shell.execute_reply.started": "2021-05-17T23:27:15.166374Z"
    }
   },
   "outputs": [],
   "source": [
    "new_embeddings = image_encoder(img_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:16.366074Z",
     "iopub.status.busy": "2021-05-17T23:27:16.365827Z",
     "iopub.status.idle": "2021-05-17T23:27:16.370513Z",
     "shell.execute_reply": "2021-05-17T23:27:16.369708Z",
     "shell.execute_reply.started": "2021-05-17T23:27:16.366042Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_encoder(text, device):\n",
    "    with torch.no_grad():\n",
    "        text = clip.tokenize(text).to(device)\n",
    "        text_features = model.encode_text(text)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    return(text_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexer\n",
    "\n",
    "Annoy treemap or FAISS or other solutions. Given a dataset of tensors, returns a dictionary or database or treemap structure, something that is searchable for later. It would be nice to be able to diff this somehow, or make sure that it's up-to-date. Maybe keeping two copies is okay? One for backup and quick-searching, one for main search once it's indexed any new images. \n",
    "\n",
    "This executor `needs` both Encoder and Loader to send it the new and old vectors, respectively. So it needs to be preceded by some kind of **join_all** component that can makesure we're not missing new data before handing it over to the indexer. Hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:22.830650Z",
     "iopub.status.busy": "2021-05-17T23:27:22.829915Z",
     "iopub.status.idle": "2021-05-17T23:27:22.835413Z",
     "shell.execute_reply": "2021-05-17T23:27:22.834944Z",
     "shell.execute_reply.started": "2021-05-17T23:27:22.830565Z"
    }
   },
   "outputs": [],
   "source": [
    "root = Path(args['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:23.548128Z",
     "iopub.status.busy": "2021-05-17T23:27:23.547975Z",
     "iopub.status.idle": "2021-05-17T23:27:23.551213Z",
     "shell.execute_reply": "2021-05-17T23:27:23.550679Z",
     "shell.execute_reply.started": "2021-05-17T23:27:23.548112Z"
    }
   },
   "outputs": [],
   "source": [
    "def join_all(db, new_files, new_embeddings):\n",
    "    for i, file in enumerate(new_files):\n",
    "        path, slug = file\n",
    "        start = len(db)\n",
    "        index = i + start\n",
    "        archive_db[slug] = {\n",
    "            'slug': slug,\n",
    "            'fpath': path,\n",
    "            'embed': new_embeddings[i],\n",
    "            'index': index\n",
    "        }\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:26.689841Z",
     "iopub.status.busy": "2021-05-17T23:27:26.689681Z",
     "iopub.status.idle": "2021-05-17T23:27:26.692632Z",
     "shell.execute_reply": "2021-05-17T23:27:26.691974Z",
     "shell.execute_reply.started": "2021-05-17T23:27:26.689825Z"
    }
   },
   "outputs": [],
   "source": [
    "db = join_all(archive_db,\n",
    "         new_files,\n",
    "         new_embeddings\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:27.321954Z",
     "iopub.status.busy": "2021-05-17T23:27:27.321741Z",
     "iopub.status.idle": "2021-05-17T23:27:27.326550Z",
     "shell.execute_reply": "2021-05-17T23:27:27.325029Z",
     "shell.execute_reply.started": "2021-05-17T23:27:27.321935Z"
    }
   },
   "outputs": [],
   "source": [
    "len(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And build treemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:28.602453Z",
     "iopub.status.busy": "2021-05-17T23:27:28.601731Z",
     "iopub.status.idle": "2021-05-17T23:27:28.613957Z",
     "shell.execute_reply": "2021-05-17T23:27:28.611655Z",
     "shell.execute_reply.started": "2021-05-17T23:27:28.602368Z"
    }
   },
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:29.075028Z",
     "iopub.status.busy": "2021-05-17T23:27:29.074813Z",
     "iopub.status.idle": "2021-05-17T23:27:29.078199Z",
     "shell.execute_reply": "2021-05-17T23:27:29.077644Z",
     "shell.execute_reply.started": "2021-05-17T23:27:29.075010Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_treemap(db):\n",
    "    treemap = AnnoyIndex(512, 'angular')\n",
    "    for v in db.values():\n",
    "        treemap.add_item(v['index'], v['embed'])\n",
    "\n",
    "    # Build the treemap, with 5 trees rn\n",
    "    treemap.build(5)\n",
    "\n",
    "    return(treemap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:29.615962Z",
     "iopub.status.busy": "2021-05-17T23:27:29.615800Z",
     "iopub.status.idle": "2021-05-17T23:27:47.259986Z",
     "shell.execute_reply": "2021-05-17T23:27:47.259488Z",
     "shell.execute_reply.started": "2021-05-17T23:27:29.615943Z"
    }
   },
   "outputs": [],
   "source": [
    "t = build_treemap(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:47.261342Z",
     "iopub.status.busy": "2021-05-17T23:27:47.261093Z",
     "iopub.status.idle": "2021-05-17T23:27:47.265327Z",
     "shell.execute_reply": "2021-05-17T23:27:47.264924Z",
     "shell.execute_reply.started": "2021-05-17T23:27:47.261322Z"
    }
   },
   "outputs": [],
   "source": [
    "t.get_n_items(), t.get_n_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:47.266399Z",
     "iopub.status.busy": "2021-05-17T23:27:47.266168Z",
     "iopub.status.idle": "2021-05-17T23:27:47.269406Z",
     "shell.execute_reply": "2021-05-17T23:27:47.269053Z",
     "shell.execute_reply.started": "2021-05-17T23:27:47.266382Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_archives(root, treemap, db):\n",
    "    dbpath = root/'memery.pt'\n",
    "    if dbpath.exists():\n",
    "#         dbpath.rename(root/'memery-bak.pt')\n",
    "        dbpath.unlink()\n",
    "    torch.save(db, dbpath)\n",
    "    \n",
    "    treepath = root/'memery.ann'\n",
    "    if treepath.exists():\n",
    "#         treepath.rename(root/'memery-bak.ann')\n",
    "        treepath.unlink()\n",
    "    treemap.save(str(treepath))\n",
    "    \n",
    "    return(str(dbpath), str(treepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:47.270195Z",
     "iopub.status.busy": "2021-05-17T23:27:47.270078Z",
     "iopub.status.idle": "2021-05-17T23:27:47.361769Z",
     "shell.execute_reply": "2021-05-17T23:27:47.361432Z",
     "shell.execute_reply.started": "2021-05-17T23:27:47.270180Z"
    }
   },
   "outputs": [],
   "source": [
    "save_archives(root, t, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker\n",
    "\n",
    "Takes a query and an index and finds the nearest neighbors or most similar scores. Ideally this is just a simple Annoy `get_nns_by_vector`, or in the simple case a similarity score across all the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:55.387079Z",
     "iopub.status.busy": "2021-05-17T23:27:55.386363Z",
     "iopub.status.idle": "2021-05-17T23:27:55.397260Z",
     "shell.execute_reply": "2021-05-17T23:27:55.394454Z",
     "shell.execute_reply.started": "2021-05-17T23:27:55.386997Z"
    }
   },
   "outputs": [],
   "source": [
    "def ranker(query_vec, treemap):\n",
    "    nn_indexes = treemap.get_nns_by_vector(query_vec[0], treemap.get_n_items())\n",
    "    return(nn_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:26:15.001671Z",
     "iopub.status.busy": "2021-05-17T23:26:15.001534Z",
     "iopub.status.idle": "2021-05-17T23:26:15.004383Z",
     "shell.execute_reply": "2021-05-17T23:26:15.003536Z",
     "shell.execute_reply.started": "2021-05-17T23:26:15.001654Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:56.008469Z",
     "iopub.status.busy": "2021-05-17T23:27:56.008293Z",
     "iopub.status.idle": "2021-05-17T23:27:56.012267Z",
     "shell.execute_reply": "2021-05-17T23:27:56.011056Z",
     "shell.execute_reply.started": "2021-05-17T23:27:56.008450Z"
    }
   },
   "outputs": [],
   "source": [
    "def printi(filenames, n=5):\n",
    "    for im in filenames[:n]:\n",
    "        display(IMG(filename=im[0], width=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:55.520152Z",
     "iopub.status.busy": "2021-05-17T23:27:55.519884Z",
     "iopub.status.idle": "2021-05-17T23:27:55.524543Z",
     "shell.execute_reply": "2021-05-17T23:27:55.523632Z",
     "shell.execute_reply.started": "2021-05-17T23:27:55.520126Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_5(text):\n",
    "    query_vec = text_encoder(text, device)\n",
    "    indexes = ranker(query_vec, t)\n",
    "    filenames =[[v['fpath'] for k,v in db.items() if v['index'] == ind] for ind in indexes]\n",
    "    return(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:27:56.551897Z",
     "iopub.status.busy": "2021-05-17T23:27:56.551621Z",
     "iopub.status.idle": "2021-05-17T23:27:57.496956Z",
     "shell.execute_reply": "2021-05-17T23:27:57.496325Z",
     "shell.execute_reply.started": "2021-05-17T23:27:56.551836Z"
    }
   },
   "outputs": [],
   "source": [
    "printi(rank_5(args['query']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we have to call that a success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gateway\n",
    "\n",
    "Takes a query and processes it through either Indexing Flow or Querying Flow, passing along arguments. The main entrypoint for each iteration of the index/query process.\n",
    "\n",
    "Querying Flow can technically process either text or image search, becuase the CLIP encoder will put them into the same embedding space. So we might as well build in a method for either, and make it available to the user, since it's impressive and useful and relatively easy to build.\n",
    "\n",
    "Eventually the Gateway process probably needs to be quite complicated, for serving all the different users and for delivering REST APIs to different clients. For now we will run this locally, in a notebook. Then build out a GUI from there using `mediapy` or `widgets`. That should reveal the basic necessities of the UI, and then we can separate out the GUI client from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:28:07.161111Z",
     "iopub.status.busy": "2021-05-17T23:28:07.160442Z",
     "iopub.status.idle": "2021-05-17T23:28:07.173215Z",
     "shell.execute_reply": "2021-05-17T23:28:07.171845Z",
     "shell.execute_reply.started": "2021-05-17T23:28:07.161028Z"
    }
   },
   "outputs": [],
   "source": [
    "def indexFlow(path):\n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    filepaths = get_image_files(root)\n",
    "    archive_db, new_files = files_archive_loader(filepaths, root, device)\n",
    "    print(f\"Loaded {len(archive_db)} encodings\")\n",
    "    print(f\"Encoding {len(new_files)} new images\")\n",
    "    crafted_files = crafter(new_files, device)\n",
    "    new_embeddings = image_encoder(crafted_files, device)\n",
    "    \n",
    "    db = join_all(archive_db, new_files, new_embeddings)\n",
    "    print(\"Building treemap\")\n",
    "    t = build_treemap(db)\n",
    "    \n",
    "    print(f\"Saving {len(db)}images\")\n",
    "    save_paths = save_archives(root, t, db)\n",
    "    print(\"Done\")\n",
    "    return(save_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:28:10.313351Z",
     "iopub.status.busy": "2021-05-17T23:28:10.313166Z",
     "iopub.status.idle": "2021-05-17T23:28:28.543108Z",
     "shell.execute_reply": "2021-05-17T23:28:28.542515Z",
     "shell.execute_reply.started": "2021-05-17T23:28:10.313334Z"
    }
   },
   "outputs": [],
   "source": [
    "save_paths = indexFlow(args['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:28:28.544063Z",
     "iopub.status.busy": "2021-05-17T23:28:28.543945Z",
     "iopub.status.idle": "2021-05-17T23:28:28.547992Z",
     "shell.execute_reply": "2021-05-17T23:28:28.547123Z",
     "shell.execute_reply.started": "2021-05-17T23:28:28.544047Z"
    }
   },
   "outputs": [],
   "source": [
    "save_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:08:36.054349Z",
     "iopub.status.busy": "2021-05-17T23:08:36.054132Z",
     "iopub.status.idle": "2021-05-17T23:08:36.059544Z",
     "shell.execute_reply": "2021-05-17T23:08:36.058990Z",
     "shell.execute_reply.started": "2021-05-17T23:08:36.054324Z"
    }
   },
   "outputs": [],
   "source": [
    "def queryFlow(path, query): \n",
    "    root = Path(path)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    dbpath = root/'memery.pt'\n",
    "    db = db_loader(dbpath)\n",
    "    treepath = root/'memery.ann'\n",
    "    treemap = treemap_loader(treepath)\n",
    "    \n",
    "    if treemap == None or db == {}:\n",
    "        dbpath, treepath = indexFlow(root)\n",
    "        treemap = treemap_loader(treepath)\n",
    "        db = file\n",
    "    \n",
    "    print(f\"Searching {len(db)} images\")\n",
    "    query_vec = text_encoder(query, device)\n",
    "    indexes = ranker(query_vec, treemap)\n",
    "    ranked_files = [[v['fpath'] for k,v in db.items() if v['index'] == ind] for ind in indexes]\n",
    "    return(ranked_files)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:12:15.974818Z",
     "iopub.status.busy": "2021-05-17T23:12:15.974655Z",
     "iopub.status.idle": "2021-05-17T23:12:16.791693Z",
     "shell.execute_reply": "2021-05-17T23:12:16.791335Z",
     "shell.execute_reply.started": "2021-05-17T23:12:15.974800Z"
    }
   },
   "outputs": [],
   "source": [
    "ranked = queryFlow(args['path'], 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-17T23:12:16.792617Z",
     "iopub.status.busy": "2021-05-17T23:12:16.792501Z",
     "iopub.status.idle": "2021-05-17T23:12:16.808254Z",
     "shell.execute_reply": "2021-05-17T23:12:16.807905Z",
     "shell.execute_reply.started": "2021-05-17T23:12:16.792601Z"
    }
   },
   "outputs": [],
   "source": [
    "printi(ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive process\n",
    "Currently the objective is to take the following inputs:\n",
    "- a location with images\n",
    "- a text or image query,\n",
    "\n",
    "and return the following outputs:\n",
    "- a list of image files within that location ranked by similarity to that query,\n",
    "\n",
    "with a minimum of duplicated effort, and a general ease-of-use for both the programmer and the casual API user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "- Cleanup repo\n",
    "- Rough interactive GUI\n",
    "\n",
    "- Optimize the image loader and number of trees based on memory and db size\n",
    "- Type annotations\n",
    "\n",
    "## DONE:\n",
    "- _Code for joining archived data to new data_\n",
    "- _Code for saving indexes to archive_\n",
    "- _Flows_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
