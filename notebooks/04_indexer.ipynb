{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "Given a dataset of tensors, returns a dictionary archive and a treemap structure (and saves them to disk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joiner\n",
    "\n",
    "This executor `needs` both Encoder and Loader to send it the new and old vectors, respectively. So it needs to be preceded by the **join_all** component to make sure we're not missing new data before handing it over to the indexer -- or indexing old data that no longer exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def join_all(db, new_files, new_embeddings):\n",
    "    start = len(db)\n",
    "    for i, file in enumerate(new_files):\n",
    "        path, slug = file\n",
    "        index = i + start\n",
    "        db[index] = {\n",
    "            'slug': slug,\n",
    "            'fpath': path,\n",
    "            'embed': new_embeddings[i],\n",
    "        }\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from memery.loader import get_image_files, db_loader, archive_loader\n",
    "from memery.crafter import crafter\n",
    "from memery.encoder import image_encoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = get_image_files(root)\n",
    "archive_db = {}\n",
    "\n",
    "\n",
    "archive_db, new_files = archive_loader(filepaths, root, device)\n",
    "print(f\"Loaded {len(archive_db)} encodings\")\n",
    "print(f\"Encoding {len(new_files)} new images\")\n",
    "\n",
    "crafted_files = crafter(new_files, device)\n",
    "new_embeddings = image_encoder(crafted_files, device)\n",
    "\n",
    "db = join_all(archive_db, new_files, new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = db_loader(root/'memery.pt',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[o[0] for o in db.items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building treemap takes a long time. I don't think `annoy` uses the GPU at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_treemap(db):\n",
    "    treemap = AnnoyIndex(512, 'angular')\n",
    "    for k, v in db.items():\n",
    "        treemap.add_item(k, v['embed'])\n",
    "\n",
    "    # Build the treemap, with 5 trees rn\n",
    "    treemap.build(5)\n",
    "\n",
    "    return(treemap)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = build_treemap(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.get_n_items(), t.get_n_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_archives(root, treemap, db):\n",
    "    dbpath = root/'memery.pt'\n",
    "    if dbpath.exists():\n",
    "#         dbpath.rename(root/'memery-bak.pt')\n",
    "        dbpath.unlink()\n",
    "    torch.save(db, dbpath)\n",
    "    \n",
    "    treepath = root/'memery.ann'\n",
    "    if treepath.exists():\n",
    "#         treepath.rename(root/'memery-bak.ann')\n",
    "        treepath.unlink()\n",
    "    treemap.save(str(treepath))\n",
    "    \n",
    "    return(str(dbpath), str(treepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_archives(root, t, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
