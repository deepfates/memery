{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "\n",
    "This is just a wrapper around CLIP functions. Cool thing here is we can use the one model for both image and text!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import clip\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, _ = clip.load(\"ViT-B/32\", device, jit=False)    \n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image_encoder(img_loader, device):\n",
    "    image_embeddings = torch.tensor(()).to(device)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(img_loader):\n",
    "            batch_features = model.encode_image(images.to(device))\n",
    "            image_embeddings = torch.cat((image_embeddings, batch_features)).to(device)\n",
    "    \n",
    "    image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
    "    return(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_files = [('images/memes/Wholesome-Meme-8.jpg', 'Wholesome-Meme-8'), ('images/memes/Wholesome-Meme-1.jpg', 'Wholesome-Meme-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memery.crafter import crafter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_loader = crafter(new_files, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          ...,\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00]],\n",
      "\n",
      "         [[ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          ...,\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00]],\n",
      "\n",
      "         [[ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          ...,\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          [ 1.9303e+00,  1.9303e+00,  1.9303e+00,  ...,  1.9303e+00,\n",
      "            1.9303e+00,  1.9303e+00],\n",
      "          ...,\n",
      "          [-1.7184e-01, -3.3242e-01, -4.2001e-01,  ..., -2.0103e-01,\n",
      "           -1.4264e-01,  3.3439e-03],\n",
      "          [-4.3461e-01, -5.3680e-01, -5.3680e-01,  ..., -2.4483e-01,\n",
      "           -1.7184e-01, -6.9648e-02],\n",
      "          [-6.3899e-01, -5.6599e-01, -5.3680e-01,  ..., -1.8644e-01,\n",
      "           -2.0103e-01, -1.4264e-01]],\n",
      "\n",
      "         [[ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          [ 2.0749e+00,  2.0749e+00,  2.0749e+00,  ...,  2.0749e+00,\n",
      "            2.0749e+00,  2.0749e+00],\n",
      "          ...,\n",
      "          [-1.0124e-01, -2.6633e-01, -3.5637e-01,  ..., -5.2146e-01,\n",
      "           -4.9144e-01, -5.0645e-01],\n",
      "          [-3.7138e-01, -4.7644e-01, -4.7644e-01,  ..., -5.2146e-01,\n",
      "           -4.9144e-01, -5.3647e-01],\n",
      "          [-5.8149e-01, -5.0645e-01, -4.7644e-01,  ..., -4.6143e-01,\n",
      "           -5.3647e-01, -5.5148e-01]],\n",
      "\n",
      "         [[ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          [ 2.1459e+00,  2.1459e+00,  2.1459e+00,  ...,  2.1459e+00,\n",
      "            2.1459e+00,  2.1459e+00],\n",
      "          ...,\n",
      "          [ 1.5509e-01, -1.3329e-03, -8.6653e-02,  ..., -4.7060e-01,\n",
      "           -4.2793e-01, -3.8527e-01],\n",
      "          [-1.0087e-01, -2.0041e-01, -2.0041e-01,  ..., -4.4215e-01,\n",
      "           -3.9949e-01, -3.9949e-01],\n",
      "          [-2.9995e-01, -2.2885e-01, -2.0041e-01,  ..., -3.4261e-01,\n",
      "           -3.8527e-01, -3.8527e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in img_loader:\n",
    "    print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-480b40cf8111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-bbfbadbfbfa3>\u001b[0m in \u001b[0;36mimage_encoder\u001b[0;34m(img_loader, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mimage_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "image_embeddings = image_encoder(img_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text encoder returns a 512d vector just like the image encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def text_encoder(text, device):\n",
    "    with torch.no_grad():\n",
    "        text = clip.tokenize(text).to(device)\n",
    "        text_features = model.encode_text(text)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    return(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = text_encoder('a funny dog meme', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image_query_encoder(image, device):\n",
    "    with torch.no_grad():\n",
    "        image_embed = model.encode_image(image.unsqueeze(0).to(device))\n",
    "    image_embed = image_embed / image_embed.norm(dim=-1, keepdim=True)\n",
    "    return(image_embed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
